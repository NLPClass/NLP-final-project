{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.006459,
     "end_time": "2025-05-08T13:55:21.143009",
     "exception": false,
     "start_time": "2025-05-08T13:55:21.136550",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 📚 | Import Libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2025-05-21T08:13:20.214077Z",
     "iopub.status.busy": "2025-05-21T08:13:20.213821Z",
     "iopub.status.idle": "2025-05-21T08:13:36.175771Z",
     "shell.execute_reply": "2025-05-21T08:13:36.174916Z",
     "shell.execute_reply.started": "2025-05-21T08:13:20.214055Z"
    },
    "papermill": {
     "duration": 17.47085,
     "end_time": "2025-05-08T13:55:38.620539",
     "exception": false,
     "start_time": "2025-05-08T13:55:21.149689",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"KERAS_BACKEND\"] = \"jax\"  # or \"tensorflow\" or \"torch\"\n",
    "\n",
    "import keras_nlp\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-21T08:13:36.177918Z",
     "iopub.status.busy": "2025-05-21T08:13:36.177461Z",
     "iopub.status.idle": "2025-05-21T08:13:38.566109Z",
     "shell.execute_reply": "2025-05-21T08:13:38.565577Z",
     "shell.execute_reply.started": "2025-05-21T08:13:36.177899Z"
    },
    "papermill": {
     "duration": 2.582705,
     "end_time": "2025-05-08T13:55:41.210496",
     "exception": false,
     "start_time": "2025-05-08T13:55:38.627791",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import wandb\n",
    "\n",
    "# 將這行放在程式最前面，替換 YOUR_API_KEY 為你的實際 key\n",
    "key=\"cfbd7f24413a77f911641acae8914b1dc77e1b83\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-21T08:13:38.567084Z",
     "iopub.status.busy": "2025-05-21T08:13:38.566822Z",
     "iopub.status.idle": "2025-05-21T08:13:38.570611Z",
     "shell.execute_reply": "2025-05-21T08:13:38.569791Z",
     "shell.execute_reply.started": "2025-05-21T08:13:38.567061Z"
    },
    "papermill": {
     "duration": 0.011718,
     "end_time": "2025-05-08T13:55:41.229394",
     "exception": false,
     "start_time": "2025-05-08T13:55:41.217676",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#!pip install --upgrade wandb  # 確保使用最新版本\n",
    "#from wandb.keras import WandbCallback\n",
    "\n",
    "#wandb.login(key=\"cfbd7f24413a77f911641acae8914b1dc77e1b83\")\n",
    "#wandb.init(project=\"kerasnlp-training\", name=\"your-run-name\")  # 自訂專案與實驗名稱"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.00663,
     "end_time": "2025-05-08T13:55:41.242871",
     "exception": false,
     "start_time": "2025-05-08T13:55:41.236241",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Library Version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2025-05-21T08:13:38.571957Z",
     "iopub.status.busy": "2025-05-21T08:13:38.571556Z",
     "iopub.status.idle": "2025-05-21T08:13:38.653403Z",
     "shell.execute_reply": "2025-05-21T08:13:38.652750Z",
     "shell.execute_reply.started": "2025-05-21T08:13:38.571930Z"
    },
    "papermill": {
     "duration": 0.012127,
     "end_time": "2025-05-08T13:55:41.261744",
     "exception": false,
     "start_time": "2025-05-08T13:55:41.249617",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "print(\"TensorFlow:\", tf.__version__)\n",
    "print(\"Keras:\", keras.__version__)\n",
    "print(\"KerasNLP:\", keras_nlp.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-21T08:13:38.677122Z",
     "iopub.status.busy": "2025-05-21T08:13:38.676825Z",
     "iopub.status.idle": "2025-05-21T08:13:38.686247Z",
     "shell.execute_reply": "2025-05-21T08:13:38.685628Z",
     "shell.execute_reply.started": "2025-05-21T08:13:38.677098Z"
    },
    "papermill": {
     "duration": 0.011221,
     "end_time": "2025-05-08T13:55:41.357983",
     "exception": false,
     "start_time": "2025-05-08T13:55:41.346762",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "keras.mixed_precision.set_global_policy(\"mixed_float16\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.006926,
     "end_time": "2025-05-08T13:55:41.372060",
     "exception": false,
     "start_time": "2025-05-08T13:55:41.365134",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 📁 | Dataset Path "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-21T08:13:38.687736Z",
     "iopub.status.busy": "2025-05-21T08:13:38.687019Z",
     "iopub.status.idle": "2025-05-21T08:13:38.697703Z",
     "shell.execute_reply": "2025-05-21T08:13:38.697007Z",
     "shell.execute_reply.started": "2025-05-21T08:13:38.687712Z"
    },
    "papermill": {
     "duration": 0.011252,
     "end_time": "2025-05-08T13:55:41.390267",
     "exception": false,
     "start_time": "2025-05-08T13:55:41.379015",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "BASE_PATH = '/kaggle/input/llm-classification-finetuning'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.006791,
     "end_time": "2025-05-08T13:55:41.404196",
     "exception": false,
     "start_time": "2025-05-08T13:55:41.397405",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 📖 | Meta Data \n",
    "\n",
    "The competition dataset comprises user interactions from the ChatBot Arena. In each interaction, a judge presents one or more prompts to two different large language models and then indicates which model provided the more satisfactory response. The training data contains `55,000` rows, with an expected `25,000` rows in the test set.\n",
    "\n",
    "## Files\n",
    "\n",
    "### `train.csv`\n",
    "- `id`: Unique identifier for each row.\n",
    "- `model_[a/b]`: Model identity, present in train.csv but not in test.csv.\n",
    "- `prompt`: Input prompt given to both models.\n",
    "- `response_[a/b]`: Model_[a/b]'s response to the prompt.\n",
    "- `winner_model_[a/b/tie]`: Binary columns indicating the judge's selection (ground truth target).\n",
    "\n",
    "### `test.csv`\n",
    "- `id`: Unique identifier for each row.\n",
    "- `prompt`: Input prompt given to both models.\n",
    "- `response_[a/b]`: Model_[a/b]'s response to the prompt.\n",
    "\n",
    "> Note that each interaction may have multiple prompts and responses, but this notebook will use only **one prompt per interaction**. You can choose to use all prompts and responses. Additionally, prompts and responses in the dataframe are provided as string-formatted lists, so they need to be converted to literal lists using `eval()`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.007011,
     "end_time": "2025-05-08T13:55:41.459554",
     "exception": false,
     "start_time": "2025-05-08T13:55:41.452543",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Train Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2025-05-21T08:13:38.699291Z",
     "iopub.status.busy": "2025-05-21T08:13:38.698498Z",
     "iopub.status.idle": "2025-05-21T08:13:46.569734Z",
     "shell.execute_reply": "2025-05-21T08:13:46.569013Z",
     "shell.execute_reply.started": "2025-05-21T08:13:38.699256Z"
    },
    "papermill": {
     "duration": 7.15444,
     "end_time": "2025-05-08T13:55:48.620981",
     "exception": false,
     "start_time": "2025-05-08T13:55:41.466541",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Load Train Data\n",
    "df = pd.read_csv(f'{BASE_PATH}/train.csv') \n",
    "\n",
    "# Sample data\n",
    "# df = df.sample(frac=0.10)\n",
    "\n",
    "# Take the first prompt and its associated response\n",
    "df[\"prompt\"] = df.prompt.map(lambda x: eval(x)[0])\n",
    "df[\"response_a\"] = df.response_a.map(lambda x: eval(x.replace(\"null\",\"''\"))[0])\n",
    "df[\"response_b\"] = df.response_b.map(lambda x: eval(x.replace(\"null\", \"''\"))[0])\n",
    "\n",
    "# Label conversion\n",
    "df[\"class_name\"] = df[[\"winner_model_a\", \"winner_model_b\" , \"winner_tie\"]].idxmax(axis=1)\n",
    "df[\"class_label\"] = df.class_name.map(CFG.name2label)\n",
    "\n",
    "# Show Sample\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-21T08:13:46.570754Z",
     "iopub.status.busy": "2025-05-21T08:13:46.570453Z",
     "iopub.status.idle": "2025-05-21T08:13:46.608639Z",
     "shell.execute_reply": "2025-05-21T08:13:46.607791Z",
     "shell.execute_reply.started": "2025-05-21T08:13:46.570731Z"
    },
    "papermill": {
     "duration": 0.044288,
     "end_time": "2025-05-08T13:55:48.672982",
     "exception": false,
     "start_time": "2025-05-08T13:55:48.628694",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# 檢查缺失值\n",
    "missing_values = df.isnull().sum()\n",
    "print(\"缺失值統計：\")\n",
    "print(missing_values)\n",
    "\n",
    "# 如果你只想列出有缺失值的欄位\n",
    "missing_columns = missing_values[missing_values > 0]\n",
    "print(\"\\n有缺失值的欄位：\")\n",
    "print(missing_columns)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.007338,
     "end_time": "2025-05-08T13:55:48.687990",
     "exception": false,
     "start_time": "2025-05-08T13:55:48.680652",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-21T08:13:46.609842Z",
     "iopub.status.busy": "2025-05-21T08:13:46.609589Z",
     "iopub.status.idle": "2025-05-21T08:13:46.629882Z",
     "shell.execute_reply": "2025-05-21T08:13:46.629315Z",
     "shell.execute_reply.started": "2025-05-21T08:13:46.609817Z"
    },
    "papermill": {
     "duration": 0.021446,
     "end_time": "2025-05-08T13:55:48.716809",
     "exception": false,
     "start_time": "2025-05-08T13:55:48.695363",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Load Test Data\n",
    "test_df = pd.read_csv(f'{BASE_PATH}/test.csv')\n",
    "\n",
    "# Take the first prompt and response\n",
    "test_df[\"prompt\"] = test_df.prompt.map(lambda x: eval(x)[0])\n",
    "test_df[\"response_a\"] = test_df.response_a.map(lambda x: eval(x.replace(\"null\",\"''\"))[0])\n",
    "test_df[\"response_b\"] = test_df.response_b.map(lambda x: eval(x.replace(\"null\", \"''\"))[0])\n",
    "\n",
    "# Show Sample\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.007277,
     "end_time": "2025-05-08T13:55:48.731756",
     "exception": false,
     "start_time": "2025-05-08T13:55:48.724479",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### 查看資料狀態"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-21T08:13:46.630648Z",
     "iopub.status.busy": "2025-05-21T08:13:46.630469Z",
     "iopub.status.idle": "2025-05-21T08:13:46.886412Z",
     "shell.execute_reply": "2025-05-21T08:13:46.885797Z",
     "shell.execute_reply.started": "2025-05-21T08:13:46.630632Z"
    },
    "papermill": {
     "duration": 0.274984,
     "end_time": "2025-05-08T13:55:49.014144",
     "exception": false,
     "start_time": "2025-05-08T13:55:48.739160",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "winner = df[['winner_model_a','winner_model_b','winner_tie']].idxmax(axis=1).map({\n",
    "    'winner_model_a':'A_win',\n",
    "    'winner_model_b':'B_win',\n",
    "    'winner_tie':'Tie'\n",
    "})\n",
    "counts = winner.value_counts(normalize=True)\n",
    "counts.plot.bar(title='Winner Distribution')\n",
    "plt.ylabel('Proportion')\n",
    "plt.show()\n",
    "print(counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-21T08:13:46.887668Z",
     "iopub.status.busy": "2025-05-21T08:13:46.887397Z",
     "iopub.status.idle": "2025-05-21T08:13:46.929928Z",
     "shell.execute_reply": "2025-05-21T08:13:46.929332Z",
     "shell.execute_reply.started": "2025-05-21T08:13:46.887651Z"
    },
    "papermill": {
     "duration": 0.052538,
     "end_time": "2025-05-08T13:55:49.075017",
     "exception": false,
     "start_time": "2025-05-08T13:55:49.022479",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "pair_stats = (\n",
    "    df\n",
    "    .groupby(['model_a','model_b'])\n",
    "    .agg(total=('id','size'),\n",
    "         a_wins=('winner_model_a','sum'),\n",
    "         b_wins=('winner_model_b','sum'),\n",
    "         ties=('winner_tie','sum'))\n",
    "    .assign(\n",
    "        a_win_rate=lambda d: d['a_wins']/d['total'],\n",
    "        b_win_rate=lambda d: d['b_wins']/d['total'],\n",
    "        tie_rate=lambda d: d['ties']/d['total']\n",
    "    )\n",
    "    .sort_values('total', ascending=False)\n",
    ")\n",
    "display(pair_stats.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.008019,
     "end_time": "2025-05-08T13:55:49.091537",
     "exception": false,
     "start_time": "2025-05-08T13:55:49.083518",
     "status": "completed"
    },
    "tags": []
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.007987,
     "end_time": "2025-05-08T13:55:49.107656",
     "exception": false,
     "start_time": "2025-05-08T13:55:49.099669",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Contextualize Response with Prompt\n",
    "\n",
    "In our approach, we will contextualize each response with the prompt instead of using a single prompt for all responses. This means that for each response, we will provide the model with the same set of prompts combined with their respective response (e.g., `(P + R_A)`, `(P + R_B)`, etc.). This approach is similar to the multiple-choice question task in NLP.\n",
    "\n",
    "> Note that some prompts and responses may not be encoded with `utf-8`, resulting in errors when creating the dataloader. In such cases, we will replace them with an empty string.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-21T08:13:46.933041Z",
     "iopub.status.busy": "2025-05-21T08:13:46.932809Z",
     "iopub.status.idle": "2025-05-21T08:13:46.938145Z",
     "shell.execute_reply": "2025-05-21T08:13:46.937502Z",
     "shell.execute_reply.started": "2025-05-21T08:13:46.933018Z"
    },
    "papermill": {
     "duration": 0.01445,
     "end_time": "2025-05-08T13:55:49.130699",
     "exception": false,
     "start_time": "2025-05-08T13:55:49.116249",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Define a function to create options based on the prompt and choices\n",
    "def make_pairs(row):\n",
    "    row[\"encode_fail\"] = False\n",
    "    try:\n",
    "        prompt = row.prompt.encode(\"utf-8\").decode(\"utf-8\")\n",
    "    except:\n",
    "        prompt = \"\"\n",
    "        row[\"encode_fail\"] = True\n",
    "\n",
    "    try:\n",
    "        response_a = row.response_a.encode(\"utf-8\").decode(\"utf-8\")\n",
    "    except:\n",
    "        response_a = \"\"\n",
    "        row[\"encode_fail\"] = True\n",
    "\n",
    "    try:\n",
    "        response_b = row.response_b.encode(\"utf-8\").decode(\"utf-8\")\n",
    "    except:\n",
    "        response_b = \"\"\n",
    "        row[\"encode_fail\"] = True\n",
    "        \n",
    "    row['options'] = [f\"Prompt: {prompt}\\n\\nResponse: {response_a}\",  # Response from Model A\n",
    "                      f\"Prompt: {prompt}\\n\\nResponse: {response_b}\"  # Response from Model B\n",
    "                     ]\n",
    "    return row\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-21T08:13:46.939102Z",
     "iopub.status.busy": "2025-05-21T08:13:46.938830Z",
     "iopub.status.idle": "2025-05-21T08:14:33.862940Z",
     "shell.execute_reply": "2025-05-21T08:14:33.862126Z",
     "shell.execute_reply.started": "2025-05-21T08:13:46.939078Z"
    },
    "papermill": {
     "duration": 45.33819,
     "end_time": "2025-05-08T13:56:34.477034",
     "exception": false,
     "start_time": "2025-05-08T13:55:49.138844",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "df = df.apply(make_pairs, axis=1)  # Apply the make_pairs function to each row in df\n",
    "display(df.head(2))  # Display the first 2 rows of df\n",
    "\n",
    "test_df = test_df.apply(make_pairs, axis=1)  # Apply the make_pairs function to each row in df\n",
    "display(test_df.head(2))  # Display the first 2 rows of df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.008506,
     "end_time": "2025-05-08T13:56:34.494324",
     "exception": false,
     "start_time": "2025-05-08T13:56:34.485818",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Encoding Fail Statistics\n",
    "\n",
    "Let's examine how many samples have encoding issues. From the code below, we can see that only $1\\%$ of the samples failed to be encoded, while $99\\%$ of the samples don't have any issues. A similar pattern can be expected for the test data as well. Thus, considering empty strings for this small portion of the data will not have much impact on our training and inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-21T08:14:33.864215Z",
     "iopub.status.busy": "2025-05-21T08:14:33.863946Z",
     "iopub.status.idle": "2025-05-21T08:14:33.871882Z",
     "shell.execute_reply": "2025-05-21T08:14:33.871005Z",
     "shell.execute_reply.started": "2025-05-21T08:14:33.864187Z"
    },
    "papermill": {
     "duration": 0.017467,
     "end_time": "2025-05-08T13:56:34.520313",
     "exception": false,
     "start_time": "2025-05-08T13:56:34.502846",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "df.encode_fail.value_counts(normalize=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.008258,
     "end_time": "2025-05-08T13:56:34.537114",
     "exception": false,
     "start_time": "2025-05-08T13:56:34.528856",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 🎨 | Exploratory Data Analysis (EDA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.008673,
     "end_time": "2025-05-08T13:56:34.554227",
     "exception": false,
     "start_time": "2025-05-08T13:56:34.545554",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## LLM Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-21T08:14:33.873211Z",
     "iopub.status.busy": "2025-05-21T08:14:33.872847Z",
     "iopub.status.idle": "2025-05-21T08:14:34.082200Z",
     "shell.execute_reply": "2025-05-21T08:14:34.081470Z",
     "shell.execute_reply.started": "2025-05-21T08:14:33.873192Z"
    },
    "papermill": {
     "duration": 0.19646,
     "end_time": "2025-05-08T13:56:34.759270",
     "exception": false,
     "start_time": "2025-05-08T13:56:34.562810",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import plotly.io as pio\n",
    "pio.renderers.default = 'notebook_connected'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2025-05-21T08:14:34.083260Z",
     "iopub.status.busy": "2025-05-21T08:14:34.083042Z",
     "iopub.status.idle": "2025-05-21T08:14:35.276396Z",
     "shell.execute_reply": "2025-05-21T08:14:35.275669Z",
     "shell.execute_reply.started": "2025-05-21T08:14:34.083243Z"
    },
    "papermill": {
     "duration": 1.37926,
     "end_time": "2025-05-08T13:56:36.147532",
     "exception": false,
     "start_time": "2025-05-08T13:56:34.768272",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "model_df = pd.concat([df.model_a, df.model_b])\n",
    "counts = model_df.value_counts().reset_index()\n",
    "counts.columns = ['LLM', 'Count']\n",
    "\n",
    "# Create a bar plot with custom styling using Plotly\n",
    "fig = px.bar(counts, x='LLM', y='Count',\n",
    "             title='Distribution of LLMs',\n",
    "             color='Count', color_continuous_scale='viridis')\n",
    "\n",
    "fig.update_layout(xaxis_tickangle=-45)  # Rotate x-axis labels for better readability\n",
    "\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.008698,
     "end_time": "2025-05-08T13:56:36.166864",
     "exception": false,
     "start_time": "2025-05-08T13:56:36.158166",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Winning Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2025-05-21T08:14:35.277564Z",
     "iopub.status.busy": "2025-05-21T08:14:35.277204Z",
     "iopub.status.idle": "2025-05-21T08:14:35.364676Z",
     "shell.execute_reply": "2025-05-21T08:14:35.364050Z",
     "shell.execute_reply.started": "2025-05-21T08:14:35.277543Z"
    },
    "papermill": {
     "duration": 0.069788,
     "end_time": "2025-05-08T13:56:36.245543",
     "exception": false,
     "start_time": "2025-05-08T13:56:36.175755",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "counts = df['class_name'].value_counts().reset_index()\n",
    "counts.columns = ['Winner', 'Win Count']\n",
    "\n",
    "fig = px.bar(counts, x='Winner', y='Win Count',\n",
    "             title='Winner distribution for Train Data',\n",
    "             labels={'Winner': 'Winner', 'Win Count': 'Win Count'},\n",
    "             color='Winner', color_continuous_scale='viridis')\n",
    "\n",
    "fig.update_layout(xaxis_title=\"Winner\", yaxis_title=\"Win Count\")\n",
    "\n",
    "fig.show()\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "databundleVersionId": 9809560,
     "sourceId": 86518,
     "sourceType": "competition"
    },
    {
     "modelId": 2820,
     "modelInstanceId": 4684,
     "sourceId": 6063,
     "sourceType": "modelInstanceVersion"
    },
    {
     "modelId": 2820,
     "modelInstanceId": 4686,
     "sourceId": 6065,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 23761.398896,
   "end_time": "2025-05-08T20:31:18.155391",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-05-08T13:55:16.756495",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
